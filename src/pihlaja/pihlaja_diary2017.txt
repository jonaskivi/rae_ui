2017.3.26 Sunday

Started HdrFlow last monday. Used OpenCV for Optical Flow and FFMPEG for video loading. It has been fast and fun.
Program structure is difficult. I'm sure I'll have trouble with it later. I guess I'll just have to think how to use
less state, and "tell, don't ask" -principle. And to look at my dependencies to be more sane.

I need to put stuff into Pihlaja main class instead of letting the systems handle too much. The main class should
ask the systems to do tasks, and combine the systems together into one system, instead of the systems knowing too
much about each other.

Now I'm thinking, I need some quick way to do a UI system. I have the old NanoVG example project that has some funny
custom windows flying around, and it's a nice project. But my new thinking would be to make it more like a component UI
system. Instead of everything deriving from the Rectangle uber-class, I need to have a rectangle component.
And actually better is to split the visual and the logical functionality into separate components.
In Unity they have the Image component and it is the visual. Then they have a Button component which is the clickable logic. And both of these use the Rect Transform 2D component as their data.

In Rae UI we should have probably something like:

Rect Transform -> Rectangle : the position, size and layout data.
Image -> Image : The visual representation. I guess we should make a wrapper class for ImageBuffer. But why?


2017.3.30 Thursday

class Rectangle
{
	// position in relation to pivot
	vec3 position
	float width
	float height

	// relative diffs in relation to anchors if anchors are spread out.
	float left;
	float right;
	float top;
	float bottom;

	// Anchors are normalized positions in the parent rectangle where this rectangle is anchored to.
	// In Unity, if the anchors min and max are the same, then use position, width and height coords.
	// If the anchors are spread out (different min & max) then use relative left, right etc coords.
	// These are also separated by X and Y min and max.
	vec2 minAnchor; // lower left corner anchor in parent
	vec2 maxAnchor; // upper right corner anchor in parent

	// Pivot determines the internal center from where the position is calculated.
	// It is between 0.0f and 1.0f in both x and y. Y-positive is up.
	// 0,1-----1,1
	// |         |
	// |         |
	// 0,0-----1,0
	vec2 pivot;
	qua rotation;
	vec3 scale;
}

// Hmm This Unity way seems to have a very high learning curve. I've looked at these coord systems for a couple
of months, and still I find it un-intuitive to figure out which parameter is affecting what. And Unity's
automatic compensation system is not helping either. It is just awful.

So how to do layout, and what I'd like to see, and what would I expect.
Simple Rectangles.
Which is better:
pivot in center
or pivot in top right corner?

What to think of Y-up in UI coords?

What did we have in old Rae UI?

3D-space:

Preferred coordinate system:

Maya, Right handed coordinate system
Y-up, Z-out, X-right


   +Y
    |
    |
    |----+X
   /
  /
+Z

This is best because in a 3D-editor the user can easily manipulate all axes.
If Z was going into the screen, then it is more difficult to manipulate it.
This is also Maya and OpenGL convention.

2D-space:

School books always have it like this:
   +Y
    |
    |
    |----+X

But reading direction is Y-down. What to do here...

Y-up is more natural because plus means going up, and minus means going down.

Then center or lower left corner for origin?
Center.
Have an interface class, and let the user use pixel sizes if they want.
Pixel sizes are 1920x1080 virtual resolution pixel sizes.

Hmm. Should we then just use virtual resolution pixel sizes everywhere. But it doesn't make sense.
It is such a random resolution. But at least you get the pixels to match on Full-Hd...
2000x1000 would be much better, but then again, that would just create a funny scaling offset artifact.

1.777 x 1.0
vs
1920.0 x 1080.0
Stored in the Rectangles.
1.0 is better for 3D UIs, but virtual resolution is better for everything else.

0,1-----1,1
|         |
|         |
0,0-----1,0

2---------3
|         |
|         |
0---------1

But with the center thing we get:
0.0 0.0 center
1920 width 1080 height
+960 and +540. Better learn those numbers then.

Screen start is at -960, -540

2017.4.4 Monday

- Refactored to use the TransformSystem.
Thinking about how does UI map into components? We have the Transform (pos rot scale) for the Rectangle.
What else do we need?

// Extents has the problem, that all Rectangles have a center pivot, and the sides are mirrored to an uniform shape.
// If we need to rotate in a non centered way, this becomes a problem, so please no Extents.
struct Extents
{
	vec3 extents;
}

// 2D rectangle has the problem that it is 2D. This is a 3D system. Why not just make it 3D from the start.
// A 2D rect is just a 3D box with 0.0f Z-depth.
struct Rectangle
{
}

// NanoVG can only render 2D on its own. We can of course render that 2D into a framebuffer object (Material)
// and so we can have 3D objects with NanoVG stuff on them.
// But if we go with 3D Box, we could use a special 2D rendering mode, where we just use NanoVG directly.
struct Box
{
	vec3 min;
	vec3 max;
}
or
struct Box
{
	vec3 ;
	vec3 max;
}

class UISystem
{
	Table<Box> m_boxes;
}

2------------------------------3
|                              |
|                              |
|                              |
|                              |
|                              |
|                              |
|                              |
|                              |
|                              |
|                              |
|                              |
|                              |
|                              |
0------------------------------1


2017.12.22

Good string functions for doing permutations:

std::random_shuffle(name.begin(), name.end());
std::next_permutation(name.begin(), name.end());
std::prev_permutation(name.begin(), name.end());

2018.01.11

I tested a couple parallel_for implementations and this was slightly slower:

template<typename Index, typename Callable>
static void parallel_for(Index start, Index end, Callable func)
{
	// Estimate number of threads in the pool
	const static unsigned nb_threads_hint = std::thread::hardware_concurrency();
	const static unsigned nb_threads = (nb_threads_hint == 0u ? 8u : nb_threads_hint);

	// Size of a slice for the range functions
	Index n = end - start + 1;
	Index slice = (Index) std::round(n / static_cast<double> (nb_threads));
	slice = std::max(slice, Index(1));

	// [Helper] Inner loop
	auto launchRange = [&func] (int k1, int k2)
	{
		for (Index k = k1; k < k2; ++k)
		{
			func(k);
		}
	};

	// Create pool and launch jobs
	std::vector<std::thread> pool;
	pool.reserve(nb_threads);
	Index i1 = start;
	Index i2 = std::min(start + slice, end);
	for (unsigned i = 0; i + 1 < nb_threads && i1 < end; ++i)
	{
		pool.emplace_back(launchRange, i1, i2);
		i1 = i2;
		i2 = std::min(i2 + slice, end);
	}

	if (i1 < end)
	{
		pool.emplace_back(launchRange, i1, end);
	}

	// Wait for jobs to finish
	for (std::thread& t : pool)
	{
		if (t.joinable())
		{
			t.join();
		}
	}
}

and this was the slighly faster version:

template<typename Callable>
static void parallel_for(int start, int end, Callable func)
{
	const static size_t threadCountHint = std::thread::hardware_concurrency();
	const static size_t threadCount = (threadCountHint == 0 ? 8 : threadCountHint);

	std::vector<std::thread> threads(threadCount);

	for (int t = 0; t < threadCount; ++t)
	{
		threads[t] = std::thread(std::bind(
		[&](const int bi, const int ei, const int t)
		{
			for (int j = bi; j < ei; ++j)
			{
				func(j);
			}
		}, t * end / threadCount, (t+1) == threadCount ? end : (t+1) * end / threadCount, t));
	}

	std::for_each(threads.begin(),threads.end(), [](std::thread& x)
	{
		x.join();
	});
}

2018.04.27

I think that Y-up is a mistake in 3D. Because of mathematics, architecture, level design etc.
Adopted Z-up, X-forward, Y-left (aka Z-up right handed) coordinate system.
Other major projects using it: 3DS Max, Blender, Source Engine, Cry Engine.
Most games are heavy in level design, so the XY-plane is best to be the ground plane (in 3D).
If the game is a 2D or 2.5D game then it kind of makes sense to use Y-up.

Also I think there is no point in trying to match the 3D and the 2D (UI) coordinate systems.
3D is a space, so it feels more natural to have a center point at 0,0,0 in the middle of the screen and Z-up (or Y-up).
For 2D the natural space might be more that of an image. The screen is an image not a space. Maybe.
So for an image, it makes sense to have top-left origin, instead of center. Then your width matches your max X-value etc.
and you don't have to deal with half extents etc.

But I'm kind of on the edge with this one, as 2D origin in the center feels attractive too. Then I'd probably use Y-up
instead of Y-down. Hmm. Difficult decisions.
Center origin makes centering easy.

But for default, I'd say top-left origin Y-up is best for UI thinking. UI consists mostly of images and text, and their
coordinates are like that.

For centering we could use anchors.

So, maybe an anchor component? And if it is missing, we presume top-left?

enum class AnchorType
{
	TopLeft,
	TopRight,
	BottomLeft,
	BottomRight,
	Center,
};

Do we need more precise anchors? Like I think Unity uses min max based anchors. But in Unity they are really strange, in
the way they change the basic coordinate unit behaviour. Anchor 0.5, 0.5 gives you Pos and Widht/Height controls. Any
other anchor min/max (like min 0.2 max 0.7) gives you left and right controls in relation to the anchor, which is in
relation to the parent. So X anchor min 0.0 max 0.0, Y anchor min 1.0 max 1.0 gives you top-left anchor, because Unity UI
is Y-up.

So let's stick to a simple anchor for now. Then a simple Rectangle class instead of the Position and Box (with 3D extents)
mess that we are now. Hmm. 3D UI still sounds interesting. Rectangle with Z-value?

class Rectangle
{
	float x;
	float y;
	float width;
	float height;
	float depth; // z-depth...
};

Or a depth component? Hmm. Sounds too small and creates too many ifs. And what about z-position.

Let's rewrite that with vec2's, because I sometimes think, that things should be grouped logically.

class Rectangle
{
	vec3 position;
	vec3 size;
};

Hah, used vec3 instead. Now there's a class that looks logical.

class Box
{
	vec3 position;
	vec3 extents;
};

Hmm. Could we use both Boxes and Rectangles and have the origin different...? Probably not.

What about absolute coords versus relative coords? Relative would be 0.0 -> 1.0 of parent width/height. And absolute
in our preferred coordinates (probably mm, yes millimetres, which are then converted to pixels).

Position and size in relative? Pivot in relative? Hmm. Probably need to offer both variants, but can you mix them?
Like X in absolute, and Y in relative, and mix position Y and size Y etc.

class RectangleRelative
{
	vec3 position; // from 0 to 1
	vec3 size; // from 0 to 1
};

or just Coordinates component:

enum class CoordinatesType
{
	Absolute,
	Relative
}

I forecast ifs in either case. NOPE let's not do this, if we don't need to. Use absolute for Rects, and relative for
layouts.

------------------------------------------------------------------------------------------------------------------------

Pivots are an interesting subject. Especially with rotation.

So an anchor enum, and a free pivot? The pivot only affects rotation?

class Pivot
{
	vec2 position;
};

What about terminology like Offset? Hmm. Is it the opposite of pivot? Don't like it.

Without pivots, we must define the position to be either
center (with half-extents defining the size) or
top left (with width height defining the size).
Anchor feels like it's exactly the same concept as Pivot.
Except in this case we would have Anchor to be an enum with fixed positions, and the Pivot would have free positioning.
Hmm...

Maybe it would be good to have only one of those Anchors or Pivots, and just choose if we want fixed Anchors/Pivots or
free Anchors/Pivots?

I presume we would want free Pivots, because otherwise we restrict that certain kind of UI elements are not possible.

So, scrap the Anchor thing, and use Pivots instead.

What about: should the Pivot be a separate optional component, or should the Box, Rectangle or Cube have it as a member?

----------> Usually pivots are done with the scene graph. So a pivot is just a parent. You would then lose the parent widget
-> child widget relationship, because you get this middle pivot in the hierarchy then...


------------------------------------------------------------------------------------------------------------------------

What's even more interesting is Layout objects.
Especially Layout Lines.

You can connect objects to multiple layout lines.

- Layout line controlling the center of an object.
- LL controlling left side of rectangle, another LL controlling right side. Can't have third for middle.
It's either the center, one side or two sides. For X and Y separately.

- Then there's also relative vs absolute offsets with LL. How about no offsets? If you need to offset, move the line,
or make another line.
- Margins can be done with LL's.
- Layout Points. You get X and Y easily. Basically the cross of two lines.
- Layout Rectangles (4 lines)

------------------------------------------------------------------------------------------------------------------------

Ok. Rectangle position must always be in absolute local coords.
But Layout objects could be in relative coords. Do they need to be optionally in fixed coords?

Anchor = LayoutPoint
LayoutLine, horizontal, vertical, free?
LayoutRectangle
LayoutGrid, more versatile than rectangle, vertical box or horizontal box. Can do all three.

x LayoutPoint

----------------------------- LayoutLine, horizontal

------------------
|       |        |
------------------
|       |        |
------------------ LayoutGrid, 2 columns, 2 rows

---------
|       |
--------- also LayoutGrid, with 1 column and 1 row

Parenting is one kind of layout!


------------------------------------------------------------------------------------------------------------------------

Scrap this:

/*
	query<WindowEntity>(m_windows, [&](Id windowId)
	{
		m_transformSystem.processHierarchy(windowId, [&](Id id)
		{
			if (m_panels.check(id) and
				m_transformSystem.hasTransform(id) and
				m_transformSystem.hasBox(id))
			{
				const Transform& transform = m_transformSystem.getTransform(id);
				const Box& box = m_transformSystem.getBox(id);
				const Pivot& pivot = m_transformSystem.getPivot(id);

				bool hasColor = m_colors.check(id);
				bool hovered = m_selectionSystem.isHovered(id);

				renderRectangle(transform, box, pivot,
						hovered ? panelHoverColor :
						hasColor ? getColor(id) :
						panelBackgroundColor);
			}

			if (m_buttons.check(id) and
				m_transformSystem.hasTransform(id) and
				m_transformSystem.hasBox(id))
			{
				const Button& button = getButton(id);
				const Transform& transform = m_transformSystem.getTransform(id);
				const Box& box = m_transformSystem.getBox(id);
				const Pivot& pivot = m_transformSystem.getPivot(id);

				bool hasColor = m_colors.check(id);
				bool active = isActive(id);
				bool hovered = m_selectionSystem.isHovered(id);

				renderButton(button.text(), transform, box, pivot,
					(hovered and active ? buttonActiveHoverColor :
						hovered ? buttonHoverColor :
						active ? buttonActiveColor :
						hasColor ? getColor(id) :
						buttonBackgroundColor),
					(hovered and active ? buttonActiveHoverTextColor :
						hovered ? buttonHoverTextColor :
						active ? buttonActiveTextColor :
						buttonTextColor));
			}
		});
	});
*/

---------------------------------------------------------------------------------------------------------------

2018.05.24

	Scene has all the things we need in the UI scene too.
	AssetLinkSystem has some unnecessary stuff, and we probably might not need CameraSystem. (But maybe we could use it...)
	But lets move all UI Tables to ButtonSystem, LayoutSystem, UIPropertySystem? UISystem? CommonUISystem, UIUtilsSystem
	Those could be members of Scene (or UIScene if we derive).
	Or possibly UISystem could be a member of Scene and use its EntitySystem and TransformSystem, But
	still have its own ButtonSystem and LayoutSystem etc.
	Then viewports can be used to render either 3D or 2D versions of the same Scene.
	Also then a single Scene can have both 3D and 2D objects if we want so.

	Also dynamic system arrays could be interesting, but dependencies might be difficult.


2019.08.24

Long time no diary. Refactoring the Pihlaja codebase has gone really well. The scenes now have their own
systems. A lot of bugs were fixed, and the code got a lot cleaner. Especially the threading code for the
raytracer is now working as intented. The raytracer is of course still slow and CPU based. Should try to
test turning it into an OpenCL GPU raytracer with the help of some tutorials.

Since I'm on a train, on my way from Helsinki to Tampere, and I didn't have all the things installed,
which I would need to compile, I haven't been able to do any real work this time. So I might as well try
to think of widgets that we need.

- Checkbox
- Editable TextBox. Hmm. How to name these and do we need a separate Label widget. Separate from Text, which
is in a way more generic. A Label is the thing that you have in front of a TextBox telling what is the 
name of the property that it will change.
- ColorPropertyEditor
	A single textbox and a colored preview square. Ideally a color chooser popup, when clicking the square.
	Alternatively three textboxes, but then where do we put the hex value? Possibly a format chooser
	in context menu, so you can support multiple different color "systems". Float 0.0-1.0, uint8 0-256, hex?
- Vector3 and Vector4 property editor(s). Probably just the same thing?
	Label, TextBox x 3 or 4.

